#!/bin/bash
# 3ê°œì›” ì „ ì˜ˆì¸¡ì˜ ì‹¤ì œ ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
# ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
# cron: 0 2 * * 0 /path/to/scripts/update-returns.sh

# PATH ì„¤ì • (cron í™˜ê²½ìš©)
export PATH="/usr/local/bin:/usr/bin:/bin:/opt/homebrew/bin:$PATH"
export PATH="/Applications/Docker.app/Contents/Resources/bin:$PATH"

LOG_DIR="/home/ahnbi2/etf-trading-project/logs"
LOG_FILE="$LOG_DIR/update-returns-$(date +%Y%m%d).log"
PROJECT_DIR="/home/ahnbi2/etf-trading-project"

mkdir -p "$LOG_DIR"

echo "========================================" >> "$LOG_FILE"
echo "ğŸ“Š ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸ ì‹œì‘: $(date)" >> "$LOG_FILE"
echo "========================================" >> "$LOG_FILE"

cd "$PROJECT_DIR"

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ë° ì‹œì‘
if ! pgrep -f "ssh.*3306:127.0.0.1:5100" > /dev/null; then
    echo "ğŸ“¡ SSH í„°ë„ ì‹œì‘..." >> "$LOG_FILE"
    ssh -f -N -L 3306:127.0.0.1:5100 ahnbi2@ahnbi2.suwon.ac.kr \
        -o ServerAliveInterval=60 \
        -o ServerAliveCountMax=3
    sleep 3
fi

# Docker ì»¨í…Œì´ë„ˆ í™•ì¸
if ! docker ps | grep -q "etf-ml-service"; then
    echo "ğŸ³ Docker ì»¨í…Œì´ë„ˆ ì‹œì‘..." >> "$LOG_FILE"
    docker-compose up -d
    sleep 10
fi

# 2. í—¬ìŠ¤ì²´í¬
for i in {1..30}; do
    if wget -q -O- http://localhost:8000/health | grep -q "healthy"; then
        echo "âœ… ì„œë¹„ìŠ¤ ì •ìƒ" >> "$LOG_FILE"
        break
    fi
    sleep 2
done

# 3. 3ê°œì›” ì „ ì˜ˆì¸¡ ì¡°íšŒ ë° ì‹¤ì œ ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸
echo "ğŸ” 3ê°œì›” ì „ ì˜ˆì¸¡ ì¡°íšŒ ì¤‘..." >> "$LOG_FILE"

# 90ì¼ ì „ ë‚ ì§œ ê³„ì‚°
TARGET_DATE=$(date -v-90d +%Y-%m-%d 2>/dev/null || date -d "90 days ago" +%Y-%m-%d)
echo "ğŸ“… ì—…ë°ì´íŠ¸ ëŒ€ìƒ ë‚ ì§œ: $TARGET_DATE" >> "$LOG_FILE"

# TODO: ì‹¤ì œ API í˜¸ì¶œë¡œ ì—…ë°ì´íŠ¸
# í˜„ì¬ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¹€
#
# 1. GET /api/predictions?prediction_date=$TARGET_DATE
# 2. ê° ì˜ˆì¸¡ì— ëŒ€í•´ í˜„ì¬ ê°€ê²© ì¡°íšŒ
# 3. actual_close, actual_return, is_correct ì—…ë°ì´íŠ¸

echo "" >> "$LOG_FILE"
echo "ğŸ“ˆ ìˆ˜ìµë¥  ê³„ì‚° ë° ì—…ë°ì´íŠ¸..." >> "$LOG_FILE"

# Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì—…ë°ì´íŠ¸ ì‹¤í–‰
python3 << 'PYTHON_SCRIPT' >> "$LOG_FILE" 2>&1
import requests
from datetime import datetime, timedelta

API_BASE = "http://localhost:8000"
target_date = datetime.now() - timedelta(days=90)

print(f"ëŒ€ìƒ ë‚ ì§œ: {target_date.strftime('%Y-%m-%d')}")

# í•´ë‹¹ ë‚ ì§œ ì˜ˆì¸¡ ì¡°íšŒ (ì‹¤ì œë¡œëŠ” date í•„í„° í•„ìš”)
try:
    response = requests.get(f"{API_BASE}/api/predictions?limit=100")
    data = response.json()
    print(f"ì¡°íšŒëœ ì˜ˆì¸¡ ìˆ˜: {data.get('count', 0)}")

    # 3ê°œì›” ì§€ë‚œ ì˜ˆì¸¡ í•„í„°ë§
    old_predictions = [
        p for p in data.get('predictions', [])
        if datetime.fromisoformat(p['prediction_date'].replace('Z', '+00:00')).date() <= target_date.date()
    ]
    print(f"ì—…ë°ì´íŠ¸ ëŒ€ìƒ: {len(old_predictions)}ê°œ")

    # TODO: ê° ì˜ˆì¸¡ì— ëŒ€í•´ ì‹¤ì œ ìˆ˜ìµë¥  ê³„ì‚° ë° ì—…ë°ì´íŠ¸
    # - í˜„ì¬ê°€ ì¡°íšŒ: GET /api/data/{symbol}
    # - ìˆ˜ìµë¥  ê³„ì‚°: (current - predicted_close) / predicted_close * 100
    # - ì—…ë°ì´íŠ¸: PATCH /api/predictions/{id}

except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

print("ì—…ë°ì´íŠ¸ ì™„ë£Œ")
PYTHON_SCRIPT

echo "" >> "$LOG_FILE"
echo "ì™„ë£Œ ì‹œê°„: $(date)" >> "$LOG_FILE"
echo "âœ… ìˆ˜ìµë¥  ì—…ë°ì´íŠ¸ ì™„ë£Œ"
