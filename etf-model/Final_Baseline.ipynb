{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe25d6-5e95-477e-900d-fb422c935d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, warnings\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "TQDM_KW = dict(ncols=80, leave=False)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TRADING_DAYS_3M = 63\n",
    "CWD = os.getcwd()\n",
    "OUTPUT_DIR = CWD\n",
    "\n",
    "def load_tickers_from_csv(path: str) -> List[str]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"티커 CSV가 존재하지 않습니다: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"티커 CSV가 비어 있습니다: {path}\")\n",
    "\n",
    "    cols = [c for c in df.columns if c.lower() in (\"ticker\", \"symbol\", \"code\")]\n",
    "    col = cols[0] if cols else df.columns[0]\n",
    "\n",
    "    tickers = (\n",
    "        df[col].astype(str).str.strip()\n",
    "        .replace({\"\": np.nan}).dropna()\n",
    "        .drop_duplicates().tolist()\n",
    "    )\n",
    "    print(f\"[tickers] {os.path.basename(path)} → {len(tickers)}개 로드\")\n",
    "    return tickers\n",
    "\n",
    "def collect_nasdaq_meta() -> Tuple[pd.DataFrame, List[str]]:\n",
    "    df = fdr.StockListing(\"NASDAQ\")\n",
    "    syms = df[\"Symbol\"].dropna().astype(str).str.strip().tolist()\n",
    "    meta_df = df.copy()\n",
    "    meta_df[\"__key__\"] = \"Symbol\"\n",
    "    return meta_df, syms\n",
    "\n",
    "def download_fdr(tickers: List[str], start: str, end: str) -> dict:\n",
    "    data = {}\n",
    "    MIN_LEN = 1\n",
    "    for t in tqdm(tickers, desc=f\"시세 다운로드 {start}~{end}\", **TQDM_KW):\n",
    "        try:\n",
    "            df = fdr.DataReader(t, start, end)\n",
    "            if isinstance(df, pd.DataFrame) and len(df) >= MIN_LEN:\n",
    "                df = df.rename(columns=str.lower)\n",
    "                df[\"ticker\"] = t\n",
    "                cols = [c for c in [\"open\",\"high\",\"low\",\"close\",\"volume\",\"ticker\"] if c in df.columns or c==\"ticker\"]\n",
    "                data[t] = df[cols]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    px = df[\"close\"]\n",
    "    df[\"ret_1d\"]  = px.pct_change(1,  fill_method=None)\n",
    "    df[\"ret_5d\"]  = px.pct_change(5,  fill_method=None)\n",
    "    df[\"ret_20d\"] = px.pct_change(20, fill_method=None)\n",
    "    df[\"ret_63d\"] = px.pct_change(TRADING_DAYS_3M, fill_method=None)\n",
    "    df[\"target_3m\"] = px.shift(-TRADING_DAYS_3M) / px - 1\n",
    "    return df\n",
    "\n",
    "def make_panel(data_dict: dict) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for t, df in data_dict.items():\n",
    "        if \"close\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        tmp = add_features(df.copy())\n",
    "        tmp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        feat_cols = [\"ret_1d\",\"ret_5d\",\"ret_20d\",\"ret_63d\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "        available_feats = [c for c in feat_cols if c in tmp.columns]\n",
    "        tmp[available_feats] = tmp[available_feats].fillna(0)\n",
    "\n",
    "        tmp[\"date\"] = tmp.index\n",
    "        tmp[\"ticker\"] = t\n",
    "        frames.append(tmp)\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame()\n",
    "    return pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "def find_anomalous_tickers(train_df: pd.DataFrame) -> List[str]:\n",
    "    bad = []\n",
    "    grouped = train_df.groupby(\"ticker\")\n",
    "\n",
    "    for t, g in grouped:\n",
    "        closes = g[\"close\"].astype(float).values\n",
    "        if np.any(~np.isfinite(closes)) or np.any(closes <= 0):\n",
    "            bad.append(t); continue\n",
    "\n",
    "        if \"volume\" in g.columns:\n",
    "            vols = g[\"volume\"].astype(float).values\n",
    "            if np.any(~np.isfinite(vols)) or np.any(vols < 0):\n",
    "                bad.append(t); continue\n",
    "\n",
    "        if \"ret_1d\" in g.columns and g[\"ret_1d\"].abs().max() > 5.0:\n",
    "            bad.append(t); continue\n",
    "\n",
    "        cmin, cmax = closes.min(), closes.max()\n",
    "        if cmin > 0 and cmax / cmin > 1000:\n",
    "            bad.append(t); continue\n",
    "\n",
    "    bad = sorted(set(bad))\n",
    "    print(f\"- 이상치 의심 종목 수: {len(bad)}개\")\n",
    "    return bad\n",
    "\n",
    "def run_task_multi_year(\n",
    "    train_start: str,\n",
    "    train_end: str,\n",
    "    years: List[int],\n",
    "    universe_csv_template: str,\n",
    "    output_dir: str,\n",
    "    out_prefix: str = \"TS_nasdaq\",\n",
    "):\n",
    "    print(f\"\\n=== Multi-year 실행 시작 (years={years}) ===\")\n",
    "\n",
    "    # 0) 연도별 유니버스 로드 → union\n",
    "    year_to_tickers = {}\n",
    "    all_pred_tickers = set()\n",
    "    for y in years:\n",
    "        csv_path = universe_csv_template.format(year=y)\n",
    "        tickers_y = load_tickers_from_csv(csv_path)\n",
    "        year_to_tickers[y] = tickers_y\n",
    "        all_pred_tickers.update(tickers_y)\n",
    "        print(f\"- {y} 유니버스: {len(tickers_y)}개 ({os.path.basename(csv_path)})\")\n",
    "    print(f\"- 전체 예측 티커 union: {len(all_pred_tickers)}개\")\n",
    "\n",
    "    # 1) 학습 유니버스\n",
    "    meta_df, _ = collect_nasdaq_meta()\n",
    "    list_col = None\n",
    "    for cand in [\"ListingDate\",\"ListedDate\",\"IPODate\",\"상장일\",\"상장일자\"]:\n",
    "        if cand in meta_df.columns:\n",
    "            list_col = cand\n",
    "            break\n",
    "\n",
    "    if list_col is not None:\n",
    "        mdf = meta_df[[\"Symbol\", list_col]].copy()\n",
    "        mdf[\"__listdate__\"] = pd.to_datetime(mdf[list_col].astype(str).str.replace(\" \",\"\"), errors=\"coerce\")\n",
    "        train_universe = (\n",
    "            mdf[mdf[\"__listdate__\"] <= pd.to_datetime(train_end)][\"Symbol\"]\n",
    "            .astype(str).str.strip().tolist()\n",
    "        )\n",
    "    else:\n",
    "        train_universe = meta_df[\"Symbol\"].dropna().astype(str).str.strip().tolist()\n",
    "\n",
    "    train_universe = sorted(set(train_universe))\n",
    "    print(f\"- 학습용 나스닥 전체 티커 수: {len(train_universe)}개\")\n",
    "\n",
    "    # 2) 다운로드\n",
    "    total_tickers = sorted(set(train_universe) | set(all_pred_tickers))\n",
    "    print(f\"- FDR 다운로드 대상 총 티커 수: {len(total_tickers)}개\")\n",
    "\n",
    "    max_year = max(years)\n",
    "    data_end = (pd.to_datetime(f\"{max_year}-12-31\") + pd.Timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    data = download_fdr(total_tickers, train_start, data_end)\n",
    "    if not data:\n",
    "        print(\"⚠️ 다운로드된 종목이 없습니다. 스킵\")\n",
    "        return\n",
    "\n",
    "    panel = make_panel(data)\n",
    "    if panel.empty:\n",
    "        print(\"⚠️ 패널 생성 실패\")\n",
    "        return\n",
    "    panel[\"date\"] = pd.to_datetime(panel[\"date\"])\n",
    "    print(f\"- 패널 크기: {panel.shape}\")\n",
    "\n",
    "    # 3) 학습\n",
    "    FEAT_COLS = [\"ret_1d\",\"ret_5d\",\"ret_20d\",\"ret_63d\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "    train_mask = (\n",
    "        (panel[\"date\"] >= pd.to_datetime(train_start)) &\n",
    "        (panel[\"date\"] <= pd.to_datetime(train_end)) &\n",
    "        (panel[\"target_3m\"].notna())\n",
    "    )\n",
    "    train_df = panel.loc[train_mask].copy()\n",
    "    print(f\"- 이상치 제거 전 학습 데이터: {train_df.shape}\")\n",
    "\n",
    "    bad = find_anomalous_tickers(train_df)\n",
    "    if bad:\n",
    "        train_df = train_df[~train_df[\"ticker\"].isin(bad)].copy()\n",
    "        print(f\"- 이상치 제거 후 학습 데이터: {train_df.shape} (제거 {len(bad)}개)\")\n",
    "\n",
    "    X_tr = train_df[FEAT_COLS]\n",
    "    y_tr = train_df[\"target_3m\"]\n",
    "    valid = (~X_tr.isnull().any(axis=1)) & (~y_tr.isnull())\n",
    "    X_tr = X_tr[valid]\n",
    "    y_tr = y_tr[valid]\n",
    "\n",
    "    model = Pipeline([(\"scaler\", StandardScaler()), (\"ridge\", Ridge(alpha=1.0, random_state=SEED))])\n",
    "    print(\"- 모델 학습 중...\")\n",
    "    model.fit(X_tr, y_tr)\n",
    "    print(\"- 모델 학습 완료\")\n",
    "\n",
    "    # 4) 연도별 예측\n",
    "    all_dates = sorted(panel[\"date\"].unique())\n",
    "    for y in years:\n",
    "        pred_days = [d for d in all_dates if (d >= pd.to_datetime(f\"{y}-01-01\")) and (d <= pd.to_datetime(f\"{y}-12-31\"))]\n",
    "        if not pred_days:\n",
    "            print(f\"⚠️ {y}: pred_days 비어 있음 → 스킵\")\n",
    "            continue\n",
    "\n",
    "        pred_set = set(year_to_tickers[y])\n",
    "        results = []\n",
    "\n",
    "        for d in tqdm(pred_days, desc=f\"{y} 일별 예측\", **TQDM_KW):\n",
    "            day_df = panel[(panel[\"date\"] == d) & (panel[\"ticker\"].isin(pred_set))].copy()\n",
    "            if day_df.empty:\n",
    "                continue\n",
    "\n",
    "            preds = model.predict(day_df[FEAT_COLS].fillna(0))\n",
    "            k = min(100, len(day_df))\n",
    "            top_idx = np.argsort(-preds)[:k]\n",
    "            sel = day_df.iloc[top_idx]\n",
    "\n",
    "            results.append(pd.DataFrame({\n",
    "                \"date\": sel[\"date\"].dt.strftime(\"%Y-%m-%d\"),\n",
    "                \"rank\": np.arange(1, k+1, dtype=int),\n",
    "                \"ticker\": sel[\"ticker\"].astype(str),\n",
    "            }))\n",
    "\n",
    "        if results:\n",
    "            out = pd.concat(results, ignore_index=True)[[\"date\",\"rank\",\"ticker\"]]\n",
    "            out_path = os.path.join(output_dir, f\"Baseline_submission_{out_prefix}_{y}.csv\")\n",
    "            out.to_csv(out_path, index=False)\n",
    "            print(f\"✅ {y} 저장 완료 → {out_path} (rows={len(out)})\")\n",
    "        else:\n",
    "            print(f\"⚠️ {y}: 예측 결과 비어있음\")\n",
    "\n",
    "# 실행\n",
    "UNIVERSE_TEMPLATE = \"../main_round/data/universe/final_universe/{year}_final_universe.csv\"\n",
    "\n",
    "run_task_multi_year(\n",
    "    train_start=\"2010-01-01\",\n",
    "    train_end=\"2019-12-31\",\n",
    "    years=[2020, 2021, 2022, 2023, 2024],\n",
    "    universe_csv_template=UNIVERSE_TEMPLATE,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    out_prefix=\"TS_nasdaq\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldy1118",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
